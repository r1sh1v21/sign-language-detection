{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497584cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: sklearn in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.post1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.1.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.53.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (4.7.0.72)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (22.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.0.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow opencv-python sklearn matplotlib mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb78ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c79d99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: comtypes in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyttsx3) (1.1.14)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\valee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyttsx3) (306)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812dcac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "engine.say(\"jaffer is gay\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0b0fae",
   "metadata": {},
   "source": [
    "mp holistic for keypoints extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee1b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120bda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_det(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f41b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_stlyed_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1))\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf6f73",
   "metadata": {},
   "source": [
    "extracting keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "048d63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ddc75",
   "metadata": {},
   "source": [
    "creating folders for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "666f8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('MP_Data2')\n",
    "actions = np.array(['hello','you','how'])\n",
    "no_sequences = 30\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "774f2fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21873086",
   "metadata": {},
   "source": [
    "data collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "adfb99ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sequence_length):\n\u001b[0;32m      8\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 10\u001b[0m     image, results \u001b[38;5;241m=\u001b[39m \u001b[43mmediapipe_det\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholistic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#print(results)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mmediapipe_det\u001b[1;34m(image, model)\u001b[0m\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m      3\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\python\\solutions\\holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\python\\solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    361\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    362\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    363\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "time.sleep(4)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    for action in actions:\n",
    "        for sequence in range(no_sequences):\n",
    "            for frame_num in range(sequence_length):\n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                image, results = mediapipe_det(frame, holistic)\n",
    "                #print(results)\n",
    "\n",
    "                \n",
    "                if frame_num == 0:\n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),2,cv2.LINE_AA)\n",
    "                    cv2.putText(image, f'Collecting frames for {action} video number: {sequence}', (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255),1,cv2.LINE_AA)\n",
    "                    cv2.waitKey(1000)\n",
    "\n",
    "                else:\n",
    "                    cv2.putText(image, f'Collecting frames for {action} video number: {sequence}', (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255),1,cv2.LINE_AA)\n",
    "                \n",
    "                draw_stlyed_landmarks(image, results)\n",
    "                \n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "                \n",
    "                \n",
    "                cv2.imshow(\"frame\", image)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7608d105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6107305884361267"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d28dcb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99ad60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f422aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c924b",
   "metadata": {},
   "source": [
    "data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3e57009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "65bc0789",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c0b1d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'you': 1, 'how': 2}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "388f3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), f\"{frame_num}.npy\"))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e026415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80005c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "054cad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91ca6eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "17b7050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8c919",
   "metadata": {},
   "source": [
    "building and training LSTM neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bec25ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "88207813",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"Logs\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "03a7daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ed852650",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "56ccced9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 9s 288ms/step - loss: 4.8195 - categorical_accuracy: 0.1491\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 57.9392 - categorical_accuracy: 0.2807\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 61.2598 - categorical_accuracy: 0.2807\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 9.6124 - categorical_accuracy: 0.2281\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 24.4856 - categorical_accuracy: 0.1930\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 12.8312 - categorical_accuracy: 0.3158\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 16.2380 - categorical_accuracy: 0.2632\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 10.8769 - categorical_accuracy: 0.2544\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 10.4693 - categorical_accuracy: 0.2368\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 12.1633 - categorical_accuracy: 0.2982\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 10.0295 - categorical_accuracy: 0.2105\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 5.1351 - categorical_accuracy: 0.3509\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 9.9812 - categorical_accuracy: 0.2719\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 11.6630 - categorical_accuracy: 0.2368\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 5.6869 - categorical_accuracy: 0.1842\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 6.0182 - categorical_accuracy: 0.2544\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 4.3131 - categorical_accuracy: 0.2193\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 5.7033 - categorical_accuracy: 0.2632\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 5.1927 - categorical_accuracy: 0.2544\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 3.7936 - categorical_accuracy: 0.2807\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 1.9087 - categorical_accuracy: 0.2544\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 1.5020 - categorical_accuracy: 0.2544\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.4061 - categorical_accuracy: 0.2719\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.4259 - categorical_accuracy: 0.2368\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 1.4300 - categorical_accuracy: 0.2544\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.4135 - categorical_accuracy: 0.2544\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.3956 - categorical_accuracy: 0.2544\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 1.3855 - categorical_accuracy: 0.2456\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 1.3827 - categorical_accuracy: 0.2982\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.3851 - categorical_accuracy: 0.2544\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 1.3820 - categorical_accuracy: 0.2807\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.3851 - categorical_accuracy: 0.2895\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 1.3822 - categorical_accuracy: 0.2719\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 1.3793 - categorical_accuracy: 0.2719\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 1.3797 - categorical_accuracy: 0.2544\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 1.3759 - categorical_accuracy: 0.2895\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.3751 - categorical_accuracy: 0.2719\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 1.3751 - categorical_accuracy: 0.4035\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 1.3653 - categorical_accuracy: 0.3596\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.3393 - categorical_accuracy: 0.3596\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 1.4420 - categorical_accuracy: 0.2807\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 1.3763 - categorical_accuracy: 0.2632\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.3699 - categorical_accuracy: 0.2807\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 1.3656 - categorical_accuracy: 0.2895\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 1.3347 - categorical_accuracy: 0.2982\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 1.2853 - categorical_accuracy: 0.4298\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 1.2277 - categorical_accuracy: 0.3772\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 1.1487 - categorical_accuracy: 0.5175\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 1.0524 - categorical_accuracy: 0.5263\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.9975 - categorical_accuracy: 0.5789\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.9062 - categorical_accuracy: 0.6053\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 1.5195 - categorical_accuracy: 0.3333\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 1.2209 - categorical_accuracy: 0.3772\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.6079 - categorical_accuracy: 0.2982\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 1.5110 - categorical_accuracy: 0.2281\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 1.3814 - categorical_accuracy: 0.2368\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 1.3997 - categorical_accuracy: 0.2895\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.3799 - categorical_accuracy: 0.3772\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 1.3687 - categorical_accuracy: 0.3158\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.3415 - categorical_accuracy: 0.3860\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.3541 - categorical_accuracy: 0.3333\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 1.3417 - categorical_accuracy: 0.2544\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 1.3296 - categorical_accuracy: 0.2632\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.3198 - categorical_accuracy: 0.3246\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 1.2792 - categorical_accuracy: 0.3684\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.3128 - categorical_accuracy: 0.4035\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 1.2669 - categorical_accuracy: 0.4649\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 1.2380 - categorical_accuracy: 0.5175\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.2906 - categorical_accuracy: 0.4035\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.3294 - categorical_accuracy: 0.3333\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 1.3103 - categorical_accuracy: 0.3158\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.2710 - categorical_accuracy: 0.4123\n",
      "Epoch 73/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 172ms/step - loss: 1.2832 - categorical_accuracy: 0.3772\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 1.2414 - categorical_accuracy: 0.3772\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.1975 - categorical_accuracy: 0.5351\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 1.2051 - categorical_accuracy: 0.4912\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.1713 - categorical_accuracy: 0.5789\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 1.1720 - categorical_accuracy: 0.5263\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.1654 - categorical_accuracy: 0.5526\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 1.1295 - categorical_accuracy: 0.5614\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 1.1121 - categorical_accuracy: 0.5614\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 1.1325 - categorical_accuracy: 0.5439\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.1284 - categorical_accuracy: 0.4386\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.0410 - categorical_accuracy: 0.5965\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 1.1052 - categorical_accuracy: 0.5614\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 1.0800 - categorical_accuracy: 0.5351\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.0205 - categorical_accuracy: 0.5614\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.9659 - categorical_accuracy: 0.5263\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.9033 - categorical_accuracy: 0.6228\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.8396 - categorical_accuracy: 0.6228\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.8555 - categorical_accuracy: 0.5789\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.8926 - categorical_accuracy: 0.5263\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.8333 - categorical_accuracy: 0.6053\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.8371 - categorical_accuracy: 0.5789\n",
      "Epoch 95/2000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.9276 - categorical_accuracy: 0.6250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d9104011",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('finalact1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8c36e272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2a22c1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,675\n",
      "Trainable params: 596,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b9617a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fa9f1701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a7491f60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a47b3bd",
   "metadata": {},
   "source": [
    "evaluating using confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed156e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bb83207a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9957810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f91c9b71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[3, 0],\n",
       "        [0, 2]],\n",
       "\n",
       "       [[3, 0],\n",
       "        [0, 2]]], dtype=int64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7809b9a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc44c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mlt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2559a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(s):\n",
    "    engine.say(s)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('result1.mp4')\n",
    "ret, frame = cap.read()\n",
    "\n",
    "image, results = mediapipe_det(frame, holistic)        \n",
    "draw_stlyed_landmarks(image, results)\n",
    "cv2.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cdd454",
   "metadata": {},
   "source": [
    "real time detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4eb897a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "you\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "you\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "you\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "you\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "you\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "you\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "you\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "how\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "how\n"
     ]
    }
   ],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.9\n",
    "qq=0\n",
    "\n",
    "cap = cv2.VideoCapture('result1.mp4')\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image, results = mediapipe_det(frame, holistic)\n",
    "        #print(results)\n",
    "        \n",
    "        draw_stlyed_landmarks(image, results)\n",
    "        \n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res):\n",
    "                if res[np.argmax(res)] > threshold:\n",
    "                    \n",
    "                    if len(sentence) > 0:\n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "            if len(sentence) > 5:\n",
    "                sentence = sentence[-5:]\n",
    "        \n",
    "        cv2.rectangle(image, (0,0), (640,40), (245,117,16), -1)\n",
    "        \n",
    "        cv2.imshow(\"frame\", image)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "08547113",
   "metadata": {},
   "outputs": [],
   "source": [
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea9233fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speak(pred_sent(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
